#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PostgreSQL to Oracle í”„ë¡œì‹œì € ì™„ì „ ìë™ ë³€í™˜ ë„êµ¬
ì…ë ¥: postgres.sql + ast.json
ì¶œë ¥: oracle.sql
"""

import json
import os
import re
import requests
import time
from pathlib import Path

# ============================================================================
# ì„¤ì • (ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)
# ============================================================================

# ì…ë ¥ íŒŒì¼ ê²½ë¡œ
SQL_FILE_PATH = "./postgres_procedure.sql"
AST_JSON_PATH = "./procedure_ast.json"

# ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
OUTPUT_SQL_FILE = "./oracle_procedure.sql"

# LLM API ì„¤ì •
LLM_API_URL = "https://your-company-api.com/v1/chat/completions"
LLM_API_KEY = "your-api-key-here"
LLM_MODEL = "gpt-4.1"

# LLM í˜¸ì¶œ ì„¤ì •
REQUEST_TIMEOUT = 120  # íƒ€ì„ì•„ì›ƒ (ì´ˆ)
RETRY_COUNT = 3        # ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
DELAY_BETWEEN_CALLS = 2  # API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# ì²­í¬ ë¶„í•  ê¸°ì¤€
MAX_CHUNK_LINES = 300  # ì¼ë°˜ ì²­í¬ ìµœëŒ€ ë¼ì¸
MAX_CTE_LINES = 500    # CTEëŠ” ë” ê¸¸ ìˆ˜ ìˆìŒ

# ë¡œê·¸ ë””ë ‰í† ë¦¬
LOG_DIR = "./conversion_logs"

# ============================================================================
# LLM í˜¸ì¶œ í•¨ìˆ˜
# ============================================================================

def call_llm(user_message, system_message="ë‹¹ì‹ ì€ PostgreSQLì„ Oracleë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.", retry=0):
    """LLM API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": LLM_API_KEY
    }
    
    payload = {
        "messages": [
            {
                "role": "system",
                "content": system_message
            },
            {
                "role": "user",
                "content": user_message
            }
        ],
        "model": LLM_MODEL
    }
    
    try:
        response = requests.post(
            LLM_API_URL, 
            headers=headers, 
            json=payload, 
            timeout=REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ë°˜í™˜
        return response.text
        
    except requests.exceptions.RequestException as e:
        print(f"  âš ï¸  API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        
        if retry < RETRY_COUNT:
            print(f"  ğŸ”„ ì¬ì‹œë„ ì¤‘... ({retry + 1}/{RETRY_COUNT})")
            time.sleep(DELAY_BETWEEN_CALLS * 2)
            return call_llm(user_message, system_message, retry + 1)
        else:
            print(f"  âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
            return None

# ============================================================================
# íŒŒì¼ ë¡œë“œ
# ============================================================================

def load_files():
    """SQL íŒŒì¼ê³¼ AST íŒŒì¼ ë¡œë“œ"""
    
    print("ğŸ“‚ íŒŒì¼ ë¡œë”© ì¤‘...")
    
    # SQL íŒŒì¼ ì½ê¸°
    with open(SQL_FILE_PATH, 'r', encoding='utf-8') as f:
        sql_content = f.read()
        sql_lines = sql_content.split('\n')
    
    # AST JSON ì½ê¸°
    with open(AST_JSON_PATH, 'r', encoding='utf-8') as f:
        ast_data = json.load(f)
    
    print(f"  âœ“ SQL íŒŒì¼: {len(sql_lines)} ë¼ì¸")
    print(f"  âœ“ AST êµ¬ì¡° ë¡œë“œ ì™„ë£Œ")
    
    return sql_lines, ast_data

# ============================================================================
# AST ìš”ì•½ (í† í° ì ˆì•½)
# ============================================================================

def create_ast_summary(ast_data, max_depth=3, current_depth=0):
    """ASTë¥¼ ìš”ì•½í•˜ì—¬ LLM í† í° ì ˆì•½"""
    
    if current_depth >= max_depth:
        return {"type": "...", "note": "ìƒëµ"}
    
    if isinstance(ast_data, dict):
        summary = {}
        for key in ['type', 'startLine', 'endLine']:
            if key in ast_data:
                summary[key] = ast_data[key]
        
        if 'children' in ast_data and ast_data['children']:
            children = ast_data['children']
            if len(children) > 15:
                summary['children'] = [
                    create_ast_summary(children[0], max_depth, current_depth + 1),
                    {"note": f"... {len(children)-2}ê°œ ìƒëµ ..."},
                    create_ast_summary(children[-1], max_depth, current_depth + 1)
                ]
            else:
                summary['children'] = [
                    create_ast_summary(child, max_depth, current_depth + 1) 
                    for child in children
                ]
        
        return summary
    
    return ast_data

# ============================================================================
# 1ë‹¨ê³„: AST ë¶„ì„ ë° ì²­í¬ ë¶„í•  ì „ëµ
# ============================================================================

def analyze_and_chunk(sql_lines, ast_data):
    """LLMì„ í™œìš©í•œ AST ë¶„ì„ ë° ì²­í¬ ë¶„í• """
    
    print("\nğŸ” [1/4] AST êµ¬ì¡° ë¶„ì„ ë° ì²­í¬ ë¶„í•  ì „ëµ ìˆ˜ë¦½ ì¤‘...")
    
    ast_summary = create_ast_summary(ast_data)
    
    prompt = f"""
ë‹¤ìŒì€ PostgreSQL í”„ë¡œì‹œì €ì˜ AST êµ¬ì¡°ì…ë‹ˆë‹¤:
```json
{json.dumps(ast_summary, indent=2, ensure_ascii=False)}
```

ì „ì²´ ë¼ì¸ ìˆ˜: {len(sql_lines)}

ì´ í”„ë¡œì‹œì €ë¥¼ Oracleë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ì ì ˆí•œ ì²­í¬ë¡œ ë¶„í• í•˜ë ¤ê³  í•©ë‹ˆë‹¤.

**ë¶„í•  ê¸°ì¤€**:
- ì¼ë°˜ ì„¹ì…˜: ìµœëŒ€ {MAX_CHUNK_LINES} ë¼ì¸
- CTE/WITH êµ¬ë¬¸: ìµœëŒ€ {MAX_CTE_LINES} ë¼ì¸ (ê¸¸ì–´ë„ ê´œì°®ìŒ)
- ë…¼ë¦¬ì ìœ¼ë¡œ ë…ë¦½ì ì¸ ë‹¨ìœ„ë¡œ ë¶„í• 
- SELECT, INSERT, UPDATE, DELETEëŠ” ê°€ëŠ¥í•˜ë©´ ë…ë¦½ì ìœ¼ë¡œ

**ì¤‘ìš”**: ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹:
{{
  "total_lines": {len(sql_lines)},
  "structure_summary": "í”„ë¡œì‹œì € ì „ì²´ êµ¬ì¡° ê°„ëµ ìš”ì•½",
  "chunks": [
    {{
      "chunk_id": 1,
      "name": "ê°„ê²°í•œ_ì²­í¬_ì´ë¦„",
      "ast_type": "ASTì˜_ì‹¤ì œ_typeê°’",
      "start_line": 1,
      "end_line": 50,
      "size_lines": 50,
      "priority": "HIGH",
      "description": "ì´ ì„¹ì…˜ ì„¤ëª…",
      "conversion_notes": "ë³€í™˜ ì‹œ ì£¼ì˜ì‚¬í•­"
    }}
  ]
}}
"""

    response = call_llm(prompt)
    
    if not response:
        print("  âŒ AST ë¶„ì„ ì‹¤íŒ¨")
        return None
    
    # JSON ì¶”ì¶œ
    try:
        # ```json ... ``` ì œê±°
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
        if json_match:
            analysis = json.loads(json_match.group(1))
        else:
            # { ... } íŒ¨í„´ ì°¾ê¸°
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group(0))
            else:
                analysis = json.loads(response)
        
        print(f"  âœ“ ë¶„ì„ ì™„ë£Œ: {len(analysis['chunks'])}ê°œ ì²­í¬ë¡œ ë¶„í• ")
        
        # ë¡œê·¸ ì €ì¥
        save_log("analysis_result.json", analysis)
        
        return analysis
        
    except json.JSONDecodeError as e:
        print(f"  âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"  ì‘ë‹µ ë‚´ìš©:\n{response[:500]}...")
        save_log("analysis_error.txt", response)
        return None

# ============================================================================
# 2ë‹¨ê³„: ì²­í¬ë³„ ë³€í™˜
# ============================================================================

def convert_chunk(chunk, sql_lines, chunk_number, total_chunks, context):
    """ê°œë³„ ì²­í¬ë¥¼ Oracleë¡œ ë³€í™˜"""
    
    print(f"\n  ğŸ”„ [{chunk_number}/{total_chunks}] {chunk['name']} ë³€í™˜ ì¤‘...")
    print(f"     ë¼ì¸: {chunk['start_line']} ~ {chunk['end_line']} ({chunk['size_lines']} ë¼ì¸)")
    
    # SQL ì¶”ì¶œ
    start = chunk['start_line']
    end = chunk['end_line']
    sql_content = '\n'.join(sql_lines[start-1:end])
    
    # ë³€í™˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
PostgreSQL í”„ë¡œì‹œì €ì˜ ì¼ë¶€ë¥¼ Oracle 19cë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

**ì²­í¬ ì •ë³´**:
- ì²­í¬ ID: {chunk['chunk_id']}/{total_chunks}
- ì´ë¦„: {chunk['name']}
- AST íƒ€ì…: {chunk['ast_type']}
- ë¼ì¸ ë²”ìœ„: {chunk['start_line']} ~ {chunk['end_line']}
- ì„¤ëª…: {chunk['description']}
- ì£¼ì˜ì‚¬í•­: {chunk['conversion_notes']}

**ì „ì²´ ì»¨í…ìŠ¤íŠ¸**:
{context}

**ì£¼ìš” ë³€í™˜ ê·œì¹™**:
- COALESCE() â†’ NVL() ë˜ëŠ” NVL2()
- date_part(field, date) â†’ EXTRACT(field FROM date)
- substring(str, start, len) â†’ SUBSTR(str, start, len)
- now() â†’ SYSDATE
- PERFORM â†’ SELECT INTO v_dummy FROM dual
- RAISE NOTICE â†’ DBMS_OUTPUT.PUT_LINE
- VARCHAR â†’ VARCHAR2
- INTEGER â†’ NUMBER
- BOOLEAN â†’ NUMBER(1)
- string_agg() â†’ LISTAGG()
- array_agg() â†’ LISTAGG() ë˜ëŠ” COLLECT()
- CREATE OR REPLACE FUNCTION â†’ CREATE OR REPLACE PROCEDURE (RETURNS voidì¸ ê²½ìš°)
- LANGUAGE plpgsql ì œê±°
- $$ ... $$ â†’ BEGIN ... END; /

**ë³€í™˜í•  PostgreSQL ì½”ë“œ**:
```sql
{sql_content}
```

**ì¤‘ìš”**: 
1. ë³€í™˜ëœ Oracle ì½”ë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”
2. ì½”ë“œ ë¸”ë¡(```)ì´ë‚˜ "ì—¬ê¸° ë³€í™˜ëœ ì½”ë“œì…ë‹ˆë‹¤" ê°™ì€ ì„¤ëª…ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤
3. ì˜¤ì§ ì‹¤í–‰ ê°€ëŠ¥í•œ Oracle SQL ì½”ë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”
4. ì£¼ì„ìœ¼ë¡œ ì£¼ìš” ë³€ê²½ì‚¬í•­ì„ ê°„ë‹¨íˆ í‘œì‹œí•˜ì„¸ìš”
"""

    response = call_llm(prompt)
    
    if not response:
        print(f"     âŒ ë³€í™˜ ì‹¤íŒ¨")
        return None
    
    # ì½”ë“œ ë¸”ë¡ ì œê±° (```sql ... ``` ë˜ëŠ” ``` ... ```)
    oracle_code = response.strip()
    oracle_code = re.sub(r'^```sql\s*', '', oracle_code)
    oracle_code = re.sub(r'^```\s*', '', oracle_code)
    oracle_code = re.sub(r'\s*```$', '', oracle_code)
    
    print(f"     âœ“ ë³€í™˜ ì™„ë£Œ ({len(oracle_code)} ë¬¸ì)")
    
    # ë¡œê·¸ ì €ì¥
    save_log(f"chunk_{chunk['chunk_id']:03d}_original.sql", sql_content)
    save_log(f"chunk_{chunk['chunk_id']:03d}_converted.sql", oracle_code)
    
    # API í˜¸ì¶œ ê°„ ëŒ€ê¸°
    time.sleep(DELAY_BETWEEN_CALLS)
    
    return oracle_code

def convert_all_chunks(chunks, sql_lines, context):
    """ëª¨ë“  ì²­í¬ë¥¼ ë³€í™˜"""
    
    print("\nğŸ”„ [2/4] ì²­í¬ë³„ Oracle ë³€í™˜ ì¤‘...")
    
    converted_chunks = []
    total = len(chunks)
    
    for i, chunk in enumerate(chunks, 1):
        converted = convert_chunk(chunk, sql_lines, i, total, context)
        
        if converted:
            converted_chunks.append({
                'chunk_id': chunk['chunk_id'],
                'name': chunk['name'],
                'start_line': chunk['start_line'],
                'end_line': chunk['end_line'],
                'oracle_code': converted
            })
        else:
            print(f"  âš ï¸  ì²­í¬ {chunk['chunk_id']} ë³€í™˜ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
    
    print(f"\n  âœ“ {len(converted_chunks)}/{total} ì²­í¬ ë³€í™˜ ì™„ë£Œ")
    
    return converted_chunks

# ============================================================================
# 3ë‹¨ê³„: ì²­í¬ ë³‘í•©
# ============================================================================

def merge_chunks(converted_chunks, analysis):
    """ë³€í™˜ëœ ì²­í¬ë“¤ì„ í•˜ë‚˜ì˜ Oracle í”„ë¡œì‹œì €ë¡œ ë³‘í•©"""
    
    print("\nğŸ”— [3/4] ë³€í™˜ëœ ì²­í¬ ë³‘í•© ì¤‘...")
    
    # ì²­í¬ ID ìˆœìœ¼ë¡œ ì •ë ¬
    converted_chunks.sort(key=lambda x: x['chunk_id'])
    
    merged_sql = []
    
    # í—¤ë” ì¶”ê°€
    merged_sql.append("-- ============================================================================")
    merged_sql.append("-- PostgreSQL to Oracle ìë™ ë³€í™˜ ê²°ê³¼")
    merged_sql.append(f"-- ì›ë³¸: {SQL_FILE_PATH}")
    merged_sql.append(f"-- ë³€í™˜ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    merged_sql.append(f"-- ì´ ì²­í¬ ìˆ˜: {len(converted_chunks)}")
    merged_sql.append("-- ============================================================================")
    merged_sql.append("")
    
    # ê° ì²­í¬ ë³‘í•©
    for chunk in converted_chunks:
        merged_sql.append(f"-- Chunk {chunk['chunk_id']}: {chunk['name']}")
        merged_sql.append(f"-- Original lines: {chunk['start_line']} - {chunk['end_line']}")
        merged_sql.append("-" * 80)
        merged_sql.append(chunk['oracle_code'])
        merged_sql.append("")
    
    result = '\n'.join(merged_sql)
    
    print(f"  âœ“ ë³‘í•© ì™„ë£Œ ({len(result)} ë¬¸ì)")
    
    return result

# ============================================================================
# 4ë‹¨ê³„: ìµœì¢… ì •ë¦¬ ë° ê²€ì¦
# ============================================================================

def finalize_and_validate(merged_sql):
    """ìµœì¢… SQL ì •ë¦¬ ë° ê¸°ë³¸ ê²€ì¦"""
    
    print("\nâœ¨ [4/4] ìµœì¢… ì •ë¦¬ ë° ê²€ì¦ ì¤‘...")
    
    # LLMì—ê²Œ ìµœì¢… ê²€í†  ìš”ì²­
    prompt = f"""
ë‹¤ìŒì€ PostgreSQLì—ì„œ Oracleë¡œ ìë™ ë³€í™˜ëœ í”„ë¡œì‹œì €ì…ë‹ˆë‹¤.

**ê²€í†  ìš”ì²­ì‚¬í•­**:
1. ì „ì²´ì ì¸ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
2. ëˆ„ë½ëœ ë³€í™˜ì´ ìˆëŠ”ì§€ í™•ì¸
3. ë¬¸ë²• ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ í™•ì¸
4. í•„ìš”í•œ ìˆ˜ì •ì‚¬í•­ì„ ì ìš©

**ë³€í™˜ëœ ì½”ë“œ**:
```sql
{merged_sql[:10000]}  # ì²˜ìŒ 10000ìë§Œ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¦¼)
...
```

**ì¶œë ¥ í˜•ì‹**:
1. ê²€í†  ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ìš”ì•½
2. ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ìˆ˜ì •ëœ ì „ì²´ ì½”ë“œ ì¶œë ¥
3. ìˆ˜ì •ì´ í•„ìš”ì—†ë‹¤ë©´ "ê²€ì¦ ì™„ë£Œ. ìˆ˜ì • ë¶ˆí•„ìš”"ë¼ê³ ë§Œ ì¶œë ¥
"""

    print("  ğŸ” LLM ìµœì¢… ê²€ì¦ ì¤‘...")
    response = call_llm(prompt)
    
    if response and "ìˆ˜ì • ë¶ˆí•„ìš”" not in response:
        # ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ ì‹œë„
        code_match = re.search(r'```sql\s*(.*?)\s*```', response, re.DOTALL)
        if code_match:
            print("  âœ“ ìµœì¢… ìˆ˜ì • ì‚¬í•­ ì ìš©ë¨")
            return code_match.group(1)
    
    print("  âœ“ ê²€ì¦ ì™„ë£Œ")
    return merged_sql

# ============================================================================
# ë¡œê·¸ ì €ì¥
# ============================================================================

def save_log(filename, content):
    """ë¡œê·¸ íŒŒì¼ ì €ì¥"""
    
    log_path = Path(LOG_DIR)
    log_path.mkdir(exist_ok=True)
    
    filepath = log_path / filename
    
    if isinstance(content, dict):
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(content, f, indent=2, ensure_ascii=False)
    else:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(str(content))

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("\n" + "="*80)
    print("ğŸš€ PostgreSQL to Oracle ì™„ì „ ìë™ ë³€í™˜ ì‹œìŠ¤í…œ")
    print("="*80 + "\n")
    
    start_time = time.time()
    
    try:
        # 1. íŒŒì¼ ë¡œë“œ
        sql_lines, ast_data = load_files()
        
        # 2. AST ë¶„ì„ ë° ì²­í¬ ë¶„í• 
        analysis = analyze_and_chunk(sql_lines, ast_data)
        if not analysis:
            print("\nâŒ ë¶„ì„ ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        context = analysis['structure_summary']
        
        # 3. ì²­í¬ë³„ ë³€í™˜
        converted_chunks = convert_all_chunks(analysis['chunks'], sql_lines, context)
        
        if not converted_chunks:
            print("\nâŒ ë³€í™˜ëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # 4. ì²­í¬ ë³‘í•©
        merged_sql = merge_chunks(converted_chunks, analysis)
        
        # 5. ìµœì¢… ì •ë¦¬ ë° ê²€ì¦
        final_sql = finalize_and_validate(merged_sql)
        
        # 6. ìµœì¢… íŒŒì¼ ì €ì¥
        with open(OUTPUT_SQL_FILE, 'w', encoding='utf-8') as f:
            f.write(final_sql)
        
        elapsed_time = time.time() - start_time
        
        print("\n" + "="*80)
        print("âœ… ë³€í™˜ ì™„ë£Œ!")
        print("="*80)
        print(f"\nğŸ“„ ì¶œë ¥ íŒŒì¼: {OUTPUT_SQL_FILE}")
        print(f"ğŸ“Š ë³€í™˜ í†µê³„:")
        print(f"   - ì›ë³¸ ë¼ì¸ ìˆ˜: {len(sql_lines)}")
        print(f"   - ì´ ì²­í¬ ìˆ˜: {len(analysis['chunks'])}")
        print(f"   - ë³€í™˜ëœ ì²­í¬: {len(converted_chunks)}")
        print(f"   - ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
        print(f"\nğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: {LOG_DIR}/")
        print(f"   - ê° ì²­í¬ë³„ ë³€í™˜ ì „/í›„ íŒŒì¼ ì €ì¥ë¨")
        print(f"   - ë¶„ì„ ê²°ê³¼: analysis_result.json")
        print("\nâš ï¸  ë³€í™˜ëœ SQLì„ ì‹¤í–‰í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ê²€í† í•˜ì„¸ìš”!\n")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        save_log("error.txt", traceback.format_exc())

if __name__ == "__main__":
    main()
